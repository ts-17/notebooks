{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "479571df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected rows (1-based): [1, 2, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 19, 21, 22, 23, 24, 25, 26, 27]\n",
      "        y    x1   x2     x3     x4       x5       x6    x7\n",
      "0   36.98   5.1  400  51.37   4.24  1484.83  2227.25  2.06\n",
      "1   13.74  26.4  400  72.33  30.87   289.94   434.90  1.33\n",
      "3    8.53  46.4  400  79.15  44.61   164.76   247.14  0.62\n",
      "5   26.59  12.6  450  89.90  41.26   605.06   907.59  0.76\n",
      "6   19.07  18.9  450  91.48  41.88   405.37   608.05  1.71\n",
      "7    5.96  30.2  450  98.60  70.79   253.70   380.55  3.93\n",
      "8   15.52  53.8  450  98.05  66.82   142.27   213.40  1.97\n",
      "9   56.61   5.6  400  55.69   8.92  1362.24  2043.36  5.08\n",
      "10  26.72  15.1  400  66.29  17.98   507.65   761.48  0.60\n",
      "12   6.99  48.4  400  74.74  33.94   158.05   237.08  0.63\n",
      "13  45.93   5.8  425  63.71  11.95   130.66  1961.49  2.04\n",
      "14  43.09  11.2  425  67.14  14.73   682.59  1023.89  1.57\n",
      "18  26.14  16.7  450  83.88  26.33   458.42   687.62  8.82\n",
      "20  11.63  24.9  450  79.77  25.66   307.08   460.62  1.72\n",
      "21   9.59  39.5  450  87.93  22.36   193.61   290.42  1.88\n",
      "22   4.42  29.0  450  79.50  31.52   155.96   233.95  1.43\n",
      "23  38.89   5.5  460  72.73  17.86  1392.08  2088.12  1.35\n",
      "24  11.19  11.5  450  77.88  25.20   663.09   994.63  1.61\n",
      "25  75.62   5.2  470  75.50   8.66  1464.11  2196.17  4.78\n",
      "26  36.03  10.6  470  83.15  22.39   720.07  1080.11  5.88\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "csv_path = \"data-table-B5.csv\" # given by problem\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# select 20 rows at random per problem\n",
    "sample_df = df.sample(n=20, random_state=12345678).sort_index() # for reproducibility\n",
    "print(\"Selected rows (1-based):\", (sample_df.index + 1).tolist())\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8df10050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.788\n",
      "Model:                            OLS   Adj. R-squared:                  0.763\n",
      "Method:                 Least Squares   F-statistic:                     31.55\n",
      "Date:                Fri, 06 Jun 2025   Prob (F-statistic):           1.90e-06\n",
      "Time:                        10:06:07   Log-Likelihood:                -71.477\n",
      "No. Observations:                  20   AIC:                             149.0\n",
      "Df Residuals:                      17   BIC:                             151.9\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.1624      3.965      0.293      0.773      -7.203       9.528\n",
      "x6             0.0215      0.003      7.145      0.000       0.015       0.028\n",
      "x7             1.7317      1.034      1.674      0.112      -0.451       3.914\n",
      "==============================================================================\n",
      "Omnibus:                        1.046   Durbin-Watson:                   2.099\n",
      "Prob(Omnibus):                  0.593   Jarque-Bera (JB):                0.359\n",
      "Skew:                           0.324   Prob(JB):                        0.836\n",
      "Kurtosis:                       3.101   Cond. No.                     2.28e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.28e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Full model: R^2 = 0.7878, Adjusted R^2 = 0.7628\n",
      "F(2, 17) = 31.5489, p = 1.8969e-06\n",
      "\n",
      "t-tests for coefficients:\n",
      "x6: estimate = 0.0215, SE = 0.0030, t = 7.145, p = 1.6422e-06\n",
      "x7: estimate = 1.7317, SE = 1.0344, t = 1.674, p = 1.1242e-01\n",
      "\n",
      "95% CI for beta_6 and beta_7:\n",
      "beta_6: [0.0151, 0.0278]\n",
      "beta_7: [-0.4508, 3.9142]\n"
     ]
    }
   ],
   "source": [
    "# full model\n",
    "y = sample_df['y']\n",
    "X_full = sm.add_constant(sample_df[['x6', 'x7']])\n",
    "model_full = sm.OLS(y, X_full).fit()\n",
    "\n",
    "# for parts a-d (textbook problem)\n",
    "print(model_full.summary())\n",
    "\n",
    "R2_full = model_full.rsquared\n",
    "R2adj_full = model_full.rsquared_adj\n",
    "F_full = model_full.fvalue\n",
    "p_full = model_full.f_pvalue\n",
    "print(f\"\\nFull model: R^2 = {R2_full:.4f}, Adjusted R^2 = {R2adj_full:.4f}\")\n",
    "print(f\"F({int(model_full.df_model)}, {int(model_full.df_resid)}) = {F_full:.4f}, p = {p_full:.4e}\")\n",
    "\n",
    "print(\"\\nt-tests for coefficients:\")\n",
    "for var in ['x6', 'x7']:\n",
    "    tval = model_full.tvalues[var]\n",
    "    pval = model_full.pvalues[var]\n",
    "    est  = model_full.params[var]\n",
    "    se   = model_full.bse[var]\n",
    "    print(f\"{var}: estimate = {est:.4f}, SE = {se:.4f}, t = {tval:.3f}, p = {pval:.4e}\")\n",
    "\n",
    "ci_full = model_full.conf_int(alpha=0.05)\n",
    "print(\"\\n95% CI for beta_6 and beta_7:\")\n",
    "print(f\"beta_6: [{ci_full.loc['x6', 0]:.4f}, {ci_full.loc['x6', 1]:.4f}]\")\n",
    "print(f\"beta_7: [{ci_full.loc['x7', 0]:.4f}, {ci_full.loc['x7', 1]:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05c98753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.753\n",
      "Model:                            OLS   Adj. R-squared:                  0.739\n",
      "Method:                 Least Squares   F-statistic:                     54.81\n",
      "Date:                Fri, 06 Jun 2025   Prob (F-statistic):           7.26e-07\n",
      "Time:                        10:06:07   Log-Likelihood:                -73.003\n",
      "No. Observations:                  20   AIC:                             150.0\n",
      "Df Residuals:                      18   BIC:                             152.0\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          4.3308      3.654      1.185      0.251      -3.347      12.008\n",
      "x6             0.0227      0.003      7.403      0.000       0.016       0.029\n",
      "==============================================================================\n",
      "Omnibus:                        0.726   Durbin-Watson:                   1.616\n",
      "Prob(Omnibus):                  0.696   Jarque-Bera (JB):                0.107\n",
      "Skew:                           0.166   Prob(JB):                        0.948\n",
      "Kurtosis:                       3.138   Cond. No.                     1.99e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.99e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Simple model (y ~= x_6): R^2 = 0.7528, Adjusted R^2 = 0.7390\n",
      "F(1, 18) = 54.8070, p = 7.2602e-07\n",
      "95% CI for beta_6 (simple): [0.0162, 0.0291]\n",
      "\n",
      "MS_res (full model)   = 87.5645\n",
      "MS_res (simple model) = 96.3330\n"
     ]
    }
   ],
   "source": [
    "# simple model: y ~= x_6\n",
    "X_x6 = sm.add_constant(sample_df[['x6']])\n",
    "model_x6 = sm.OLS(y, X_x6).fit()\n",
    "\n",
    "# for part E\n",
    "R2_x6 = model_x6.rsquared\n",
    "R2adj_x6 = model_x6.rsquared_adj\n",
    "F_x6 = model_x6.fvalue\n",
    "p_x6 = model_x6.f_pvalue\n",
    "print(model_x6.summary())\n",
    "print(f\"Simple model (y ~= x_6): R^2 = {R2_x6:.4f}, Adjusted R^2 = {R2adj_x6:.4f}\")\n",
    "print(f\"F({int(model_x6.df_model)}, {int(model_x6.df_resid)}) = {F_x6:.4f}, p = {p_x6:.4e}\")\n",
    "\n",
    "# for f: 95% CI for beta_6 in simple model\n",
    "ci_x6 = model_x6.conf_int(alpha=0.05).loc['x6']\n",
    "print(f\"95% CI for beta_6 (simple): [{ci_x6[0]:.4f}, {ci_x6[1]:.4f}]\")\n",
    "\n",
    "# for g: compare MS_res\n",
    "MS_res_full = model_full.mse_resid\n",
    "MS_res_x6 = model_x6.mse_resid\n",
    "\n",
    "print(f\"\\nMS_res (full model)   = {MS_res_full:.4f}\")\n",
    "print(f\"MS_res (simple model) = {MS_res_x6:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e109bf87",
   "metadata": {},
   "source": [
    "The drop in $R^2$ from $0.7878 \\to 0.7528$ (about $0.035$) is quite small, and adjusted $R^2$ falls only from $0.7628 \\to 0.7390$. Adding $x_7$ to $x_6$ explains an extra $\\sim 2\\%$ of the variation in $y$, and $x_7$’s own $t$-test was not significant. $x_6$ alone captures the majority of explained variance and $x_7$’s coefficient is not significant, so the simpler model ($y \\sim x_6$) is quite reasonable.\n",
    "\n",
    "The two interval lengths ($0.0127$ vs. $0.0129$) are nearly identical. When $x_7$ is dropped from the model, the uncertainty about the slope of $x_6$ does not increase meaningfully. $x_7$ contributes relatively little to explaining $y$ once $x_6$ is in the model, because if $x_7$ had a substantial conditional effect, then removing it should have widened $\\beta_6$’s confidence band by appreciably more.\n",
    "\n",
    "Since removing $x_7$ raises the residual variance from about $87.56 \\to 96.33$, an increase of roughly $8.77$, dropping $x_7$ makes the mean-squared error grow by about 10\\%. Because $x_7$ was not significant, this modest rise in $MS_{\\text{res}}$ confirms that $x_7$’s conditional contribution is minor. $x_6$ alone explains most of the variation in $y$, so the simpler one-predictor model is both statistically defensible and substantially more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f69cdb1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
